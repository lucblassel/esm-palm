{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cfdba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    EsmForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b4d7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PRETRAINED = \"esm2_t6_8M_UR50D\" # Path to the pre-trained ESM model\n",
    "BATCH_SIZE = 10 # Training batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1c3a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(path: str, min_length=200, max_length=1024):\n",
    "    \"\"\"\n",
    "    Reads a fasta file and returns a list of sequences, and a list of sequence identifiers. \n",
    "    Sequences are filtered out if shorter than `min_length`, and truncated if longer than `max_length`.\n",
    "    \"\"\"\n",
    "    sequences, ids = [], []\n",
    "    sequence = \"\"\n",
    "    with open(path, \"r\") as fasta:\n",
    "        for line in fasta:\n",
    "            if line.startswith(\">\"):\n",
    "                if len(sequence) >= min_length:\n",
    "                    ids.append(line[1:].strip())\n",
    "                    sequences.append(sequence[:max_length])\n",
    "                sequence = \"\"\n",
    "                continue\n",
    "            sequence += line.strip()\n",
    "    if len(sequence) >= min_length:\n",
    "        ids.append(line[1:].strip())\n",
    "        sequences.append(sequence[:max_length])\n",
    "    \n",
    "    return sequences, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778669e",
   "metadata": {},
   "source": [
    "# Data Loading and preparation\n",
    "\n",
    "We use 2 datasets for training: \n",
    "\n",
    " - 10k Non-RDRP protein sequences in `datasets/rdrp_decoy.10k.fa`\n",
    " - 4627 RDRP sequences from wolf2018 in `datasets/wolf2018.fa`\n",
    "\n",
    "These are read and combined to form the training set.\n",
    "\n",
    "## Importing and formatting data\n",
    "\n",
    "The data used as input for the ESM based classifier is the set of raw sequences, truncated to a max length of 1024.  \n",
    "The labels are `1` for RDRP sequences and `0` for Non-RDRP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc42301",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sequences, pos_ids = read_fasta(\"datasets/wolf2018.fa\")\n",
    "pos_labels = [1 for _ in pos_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0bf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sequences, neg_ids = read_fasta(\"datasets/rdrp_decoy.10k.fa\")\n",
    "neg_labels = [0 for _ in neg_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91325507",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pos_sequences + neg_sequences\n",
    "labels = pos_labels + neg_labels\n",
    "ids = pos_ids + neg_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584d8a7",
   "metadata": {},
   "source": [
    "## Making datasets \n",
    "The data is then split into a training and a testing set, the sequences in each set are then tokenized using the included pretrained Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c0f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "train_sequences, test_sequences, train_labels, test_labels = (\n",
    "    train_test_split(sequences, labels, test_size=0.25, shuffle=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e24b8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PRETRAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02df30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize inputs\n",
    "train_tokenized = tokenizer(train_sequences)\n",
    "test_tokenized = tokenizer(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e28dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "\n",
    "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d6e2d",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "The sequence classifier is trained on the created dataset. Since the training data is imbalanced *(5k pos for 10k neg)* we use the F1 score to train model.  \n",
    "For evaluation we compute several metrics, to get an overall view of how the model performs:  \n",
    " - F1\n",
    " - Accuracy\n",
    " - Precision\n",
    " - Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572225b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/tmp/ipykernel_4010358/2976490373.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metrics = [load_metric(path) for path in metric_paths]\n"
     ]
    }
   ],
   "source": [
    "metric_paths = [\"./metrics/f1\", \"./metrics/accuracy\", \"./metrics/precision\", \"./metrics/recall\"]\n",
    "metrics = [load_metric(path) for path in metric_paths]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    scores = dict()\n",
    "    for metric in metrics:\n",
    "        scores.update(\n",
    "            metric.compute(predictions=predictions, references=labels)\n",
    "        )\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9163eebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at esm2_t6_8M_UR50D were not used when initializing EsmForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing EsmForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 2 # Binary classifier\n",
    "model = EsmForSequenceClassification.from_pretrained(\n",
    "    MODEL_PRETRAINED, num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da05ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_args = TrainingArguments(\n",
    "    f\"{MODEL_PRETRAINED}-finetuned-rdrp\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1354a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    trainer_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4905012e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/zeus/projets/p01/Evolbioinfo/users/lblassel/miniconda3/envs/palm-fold2/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8994\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2700\n",
      "  Number of trainable parameters = 7840642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2700' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2700/2700 06:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.086700</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>0.999142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.999571</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.999571</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.999142</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2999\n",
      "  Batch size = 10\n",
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-900\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-900/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-900/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2999\n",
      "  Batch size = 10\n",
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-1800\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-1800/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-1800/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2999\n",
      "  Batch size = 10\n",
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-2700\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-2700/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-2700/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-2700/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-2700/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from esm2_t6_8M_UR50D-finetuned-rdrp/checkpoint-1800 (score: 0.9995709995709995).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2700, training_loss=0.017897054202578686, metrics={'train_runtime': 386.5795, 'train_samples_per_second': 69.797, 'train_steps_per_second': 6.984, 'total_flos': 889892406284424.0, 'train_loss': 0.017897054202578686, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edf787e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-rdrp\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-rdrp/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-rdrp/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-rdrp/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-rdrp/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ae5ec",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "the model is then evaluated on a number of datasets:  \n",
    " - \"Original\" `rchikhi/palmesm` SerratusL training set (`datasets/eval/serratusL-negdepleted.csv`)\n",
    " - Other SerratusL negative sequences (`datasets/eval/other-negs.csv`)\n",
    " - ~~CFDL sequences (`datasets/eval/CFDL-sample.fa`)~~\n",
    " - Palmcore decoys (`datasets/eval/palmcores.fa`)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "636c43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tokenizer = AutoTokenizer.from_pretrained(f\"{MODEL_PRETRAINED}-finetuned-rdrp\")\n",
    "eval_model = EsmForSequenceClassification.from_pretrained(f\"{MODEL_PRETRAINED}-finetuned-rdrp\", num_labels=2)\n",
    "trainer = Trainer(\n",
    "    eval_model,\n",
    "    trainer_args,\n",
    "    tokenizer=eval_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff7ccc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_specificity(predictions, labels):\n",
    "    counts = Counter(zip(labels, predictions))\n",
    "    \n",
    "    TP, TN = counts[(1,1)], counts[(0,0)]\n",
    "    FP, FN = counts[(0,1)], counts[(1,0)]\n",
    "    \n",
    "    return TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1731b0a5",
   "metadata": {},
   "source": [
    "### SerratusL 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62d5d143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 43968\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7154921729439832,\n",
       " 'accuracy': 0.6283888282387191,\n",
       " 'precision': 0.5578787302794146,\n",
       " 'recall': 0.997233278322493}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/eval/serratusL-negdepleted.csv\")\n",
    "labels = [1 if label == \"rdrp\" else 0 for label in df[\"type\"].values]\n",
    "tokens = eval_tokenizer(df[\"seq\"].values.tolist())\n",
    "\n",
    "serratusL_dataset = Dataset.from_dict(tokens)\n",
    "pred_probas = trainer.predict(serratusL_dataset)\n",
    "serratusL_metrics = trainer.compute_metrics((pred_probas.predictions, labels))\n",
    "\n",
    "serratusL_metrics[\"specificity\"] = compute_specificity(\n",
    "    np.argmax(pred_probas.predictions, axis=-1), labels\n",
    ")\n",
    "\n",
    "serratusL_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63302f",
   "metadata": {},
   "source": [
    "### SerratusL other negs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44d8a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/zeus/projets/p01/Evolbioinfo/users/lblassel/miniconda3/envs/palm-fold2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.0,\n",
       " 'accuracy': 0.686,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'specificity': 0.686}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/eval/other-negs.csv\", header=None)\n",
    "df.columns = [\"seq\", \"type\"]\n",
    "labels = [1 if label == \"rdrp\" else 0 for label in df[\"type\"].values]\n",
    "tokens = eval_tokenizer(df[\"seq\"].values.tolist())\n",
    "\n",
    "serratusOther_dataset = Dataset.from_dict(tokens)\n",
    "\n",
    "pred_probas = trainer.predict(serratusOther_dataset)\n",
    "serratusOther_metrics = trainer.compute_metrics((pred_probas.predictions, labels))\n",
    "\n",
    "serratusOther_metrics[\"specificity\"] = compute_specificity(\n",
    "    np.argmax(pred_probas.predictions, axis=-1), labels\n",
    ")\n",
    "\n",
    "serratusOther_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88290e9",
   "metadata": {},
   "source": [
    "### Palmcore sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb991e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 5046\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.9557816068092174,\n",
       " 'accuracy': 0.915576694411415,\n",
       " 'precision': 0.9169488149770962,\n",
       " 'recall': 0.9980489919791893,\n",
       " 'specificity': 0.03695150115473441}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs, ids = read_fasta(\"datasets/eval/palmcores.fa\")\n",
    "labels = [0 if \"decoy\" in id else 1 for id in ids]\n",
    "tokens = eval_tokenizer(seqs)\n",
    "\n",
    "palmcore_dataset = Dataset.from_dict(tokens)\n",
    "\n",
    "pred_probas = trainer.predict(palmcore_dataset)\n",
    "palmcore_metrics = trainer.compute_metrics((pred_probas.predictions, labels))\n",
    "\n",
    "palmcore_metrics[\"specificity\"] = compute_specificity(\n",
    "    np.argmax(pred_probas.predictions, axis=-1), labels\n",
    ")\n",
    "\n",
    "palmcore_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91433d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(pred_probas.predictions, axis=1)\n",
    "decoys = [(p,t) for p,t in zip(predictions, labels) if t == 0]\n",
    "tn_idx = [i for i, (p,t) in enumerate(decoys) if p==t]\n",
    "fp_idx = [i for i, (p,t) in enumerate(decoys) if p!=t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddaca6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decoy.1D8Y_A',\n",
       " 'decoy.1XHZ_B',\n",
       " 'decoy.2ATQ_A',\n",
       " 'decoy.2DY4_B',\n",
       " 'decoy.2OYQ_B',\n",
       " 'decoy.2QV6_A',\n",
       " 'decoy.3GV5_B',\n",
       " 'decoy.5VU8_A',\n",
       " 'decoy.5XOX_C',\n",
       " 'decoy.6M7O_A',\n",
       " 'decoy.7D9U_B',\n",
       " 'decoy.A0A091DUR7_FUKDA',\n",
       " 'decoy.A0A0K0F8E6_STRVS',\n",
       " 'decoy.A0A151RAL1_CAJCA',\n",
       " 'decoy.A0A151RPT4_CAJCA',\n",
       " 'decoy.A0A158P8V2_ANGCA',\n",
       " 'decoy.A0A165CCP3_9APHY',\n",
       " 'decoy.A0A251UDF3_HELAN',\n",
       " 'decoy.A0A2K3MUJ9_TRIPR',\n",
       " 'decoy.A0A2P7YV37_9ASCO',\n",
       " 'decoy.A0A2U9C161_SCOMX',\n",
       " 'decoy.A0A319DXT4_ASPSB',\n",
       " 'decoy.A0A4E0RLC3_FASHE',\n",
       " 'decoy.A0A4W6CRS7_LATCA',\n",
       " 'decoy.A0A5F9C6V0_RABIT',\n",
       " 'decoy.A0A5F9CQF1_RABIT',\n",
       " 'decoy.A0A5F9D223_RABIT',\n",
       " 'decoy.A0A5F9DLH3_RABIT',\n",
       " 'decoy.A0A5N6P6T5_9ASTR',\n",
       " 'decoy.A0A656KFX9_BLUGR',\n",
       " 'decoy.A0A6A3BX58_HIBSY',\n",
       " 'decoy.A0A6D2JJ90_9BRAS',\n",
       " 'decoy.A0A6D2KBZ0_9BRAS',\n",
       " 'decoy.A0A7M7HK94_STRPU',\n",
       " 'decoy.U6EAV9_9EURY',\n",
       " 'decoy.giii.WP_000108316',\n",
       " 'decoy.giii.WP_000169371',\n",
       " 'decoy.giii.WP_002615862',\n",
       " 'decoy.giii.WP_003021071',\n",
       " 'decoy.giii.WP_004152765',\n",
       " 'decoy.giii.WP_005935480',\n",
       " 'decoy.giii.WP_006280223',\n",
       " 'decoy.giii.WP_006280268',\n",
       " 'decoy.giii.WP_006524762',\n",
       " 'decoy.giii.WP_006626264',\n",
       " 'decoy.giii.WP_007567572',\n",
       " 'decoy.giii.WP_007956688',\n",
       " 'decoy.giii.WP_008620137',\n",
       " 'decoy.giii.WP_009883329',\n",
       " 'decoy.giii.WP_010034068',\n",
       " 'decoy.giii.WP_010896223',\n",
       " 'decoy.giii.WP_010999330',\n",
       " 'decoy.giii.WP_010999554',\n",
       " 'decoy.giii.WP_011034594',\n",
       " 'decoy.giii.WP_011090914',\n",
       " 'decoy.giii.WP_011189748',\n",
       " 'decoy.giii.WP_011196845',\n",
       " 'decoy.giii.WP_011220889',\n",
       " 'decoy.giii.WP_011238615',\n",
       " 'decoy.giii.WP_011394089',\n",
       " 'decoy.giii.WP_011397742',\n",
       " 'decoy.giii.WP_011448352',\n",
       " 'decoy.giii.WP_011450057',\n",
       " 'decoy.giii.WP_011485487',\n",
       " 'decoy.giii.WP_011486229',\n",
       " 'decoy.giii.WP_011498880',\n",
       " 'decoy.giii.WP_011587920',\n",
       " 'decoy.giii.WP_011598972',\n",
       " 'decoy.giii.WP_011600047',\n",
       " 'decoy.giii.WP_011610123',\n",
       " 'decoy.giii.WP_011639756',\n",
       " 'decoy.giii.WP_011640454',\n",
       " 'decoy.giii.WP_011683779',\n",
       " 'decoy.giii.WP_011684311',\n",
       " 'decoy.giii.WP_011685050',\n",
       " 'decoy.giii.WP_011699998',\n",
       " 'decoy.giii.WP_011712800',\n",
       " 'decoy.giii.WP_011713626',\n",
       " 'decoy.giii.WP_011714294',\n",
       " 'decoy.giii.WP_011745321',\n",
       " 'decoy.giii.WP_011746008',\n",
       " 'decoy.giii.WP_011750763',\n",
       " 'decoy.giii.WP_011870517',\n",
       " 'decoy.giii.WP_011912970',\n",
       " 'decoy.giii.WP_011953386',\n",
       " 'decoy.giii.WP_011971756',\n",
       " 'decoy.giii.WP_011982790',\n",
       " 'decoy.giii.WP_011982869',\n",
       " 'decoy.giii.WP_012025708',\n",
       " 'decoy.giii.WP_012064452',\n",
       " 'decoy.giii.WP_012166345',\n",
       " 'decoy.giii.WP_012167571',\n",
       " 'decoy.giii.WP_012209070',\n",
       " 'decoy.giii.WP_012233364',\n",
       " 'decoy.giii.WP_012239231',\n",
       " 'decoy.giii.WP_012241889',\n",
       " 'decoy.giii.WP_012248063',\n",
       " 'decoy.giii.WP_012248065',\n",
       " 'decoy.giii.WP_012248947',\n",
       " 'decoy.giii.WP_012341372',\n",
       " 'decoy.giii.WP_012446632',\n",
       " 'decoy.giii.WP_012447173',\n",
       " 'decoy.giii.WP_012488762',\n",
       " 'decoy.giii.WP_012504683',\n",
       " 'decoy.giii.WP_012505221',\n",
       " 'decoy.giii.WP_012505670',\n",
       " 'decoy.giii.WP_012506644',\n",
       " 'decoy.giii.WP_012507238',\n",
       " 'decoy.giii.WP_012575961',\n",
       " 'decoy.giii.WP_012684507',\n",
       " 'decoy.giii.WP_012701037',\n",
       " 'decoy.giii.WP_012701051',\n",
       " 'decoy.giii.WP_012701316',\n",
       " 'decoy.giii.WP_012741696',\n",
       " 'decoy.giii.WP_012743282',\n",
       " 'decoy.giii.WP_012797163',\n",
       " 'decoy.giii.WP_012826318',\n",
       " 'decoy.giii.WP_012970052',\n",
       " 'decoy.giii.WP_013062128',\n",
       " 'decoy.giii.WP_013072725',\n",
       " 'decoy.giii.WP_013073370',\n",
       " 'decoy.giii.WP_013164608',\n",
       " 'decoy.giii.WP_013278223',\n",
       " 'decoy.giii.WP_013279065',\n",
       " 'decoy.giii.WP_013292929',\n",
       " 'decoy.giii.WP_013322552',\n",
       " 'decoy.giii.WP_013324342',\n",
       " 'decoy.giii.WP_013334973',\n",
       " 'decoy.giii.WP_013375280',\n",
       " 'decoy.giii.WP_013405636',\n",
       " 'decoy.giii.WP_013406875',\n",
       " 'decoy.giii.WP_013408147',\n",
       " 'decoy.giii.WP_013491723',\n",
       " 'decoy.giii.WP_013551929',\n",
       " 'decoy.giii.WP_013580914',\n",
       " 'decoy.giii.WP_013610569',\n",
       " 'decoy.giii.WP_013623315',\n",
       " 'decoy.giii.WP_013672260',\n",
       " 'decoy.giii.WP_013751736',\n",
       " 'decoy.giii.WP_013752711',\n",
       " 'decoy.giii.WP_013767855',\n",
       " 'decoy.giii.WP_013780091',\n",
       " 'decoy.giii.WP_013817231',\n",
       " 'decoy.giii.WP_013862778',\n",
       " 'decoy.giii.WP_013887318',\n",
       " 'decoy.giii.WP_013935017',\n",
       " 'decoy.giii.WP_013953463',\n",
       " 'decoy.giii.WP_013953498',\n",
       " 'decoy.giii.WP_013954315',\n",
       " 'decoy.giii.WP_014015629',\n",
       " 'decoy.giii.WP_014081128',\n",
       " 'decoy.giii.WP_014123481',\n",
       " 'decoy.giii.WP_014124169',\n",
       " 'decoy.giii.WP_014125822',\n",
       " 'decoy.giii.WP_014148637',\n",
       " 'decoy.giii.WP_014222172',\n",
       " 'decoy.giii.WP_014222173',\n",
       " 'decoy.giii.WP_014355548',\n",
       " 'decoy.giii.WP_014497798',\n",
       " 'decoy.giii.WP_014731166',\n",
       " 'decoy.giii.WP_014731775',\n",
       " 'decoy.giii.WP_014774764',\n",
       " 'decoy.giii.WP_014779161',\n",
       " 'decoy.giii.WP_014957559',\n",
       " 'decoy.giii.WP_015008784',\n",
       " 'decoy.giii.WP_015009964',\n",
       " 'decoy.giii.WP_015025037',\n",
       " 'decoy.giii.WP_015025480',\n",
       " 'decoy.giii.WP_015042619',\n",
       " 'decoy.giii.WP_015042961',\n",
       " 'decoy.giii.WP_015043257',\n",
       " 'decoy.giii.WP_015043757',\n",
       " 'decoy.giii.WP_015045132',\n",
       " 'decoy.giii.WP_015050279',\n",
       " 'decoy.giii.WP_015054576',\n",
       " 'decoy.giii.WP_015120113',\n",
       " 'decoy.giii.WP_015146100',\n",
       " 'decoy.giii.WP_015174455',\n",
       " 'decoy.giii.WP_015174573',\n",
       " 'decoy.giii.WP_015175488',\n",
       " 'decoy.giii.WP_015177634',\n",
       " 'decoy.giii.WP_015179483',\n",
       " 'decoy.giii.WP_015179680',\n",
       " 'decoy.giii.WP_015179816',\n",
       " 'decoy.giii.WP_015179876',\n",
       " 'decoy.giii.WP_015180007',\n",
       " 'decoy.giii.WP_015180853',\n",
       " 'decoy.giii.WP_015183188',\n",
       " 'decoy.giii.WP_015191345',\n",
       " 'decoy.giii.WP_015201683',\n",
       " 'decoy.giii.WP_015203844',\n",
       " 'decoy.giii.WP_015214816',\n",
       " 'decoy.giii.WP_015219163',\n",
       " 'decoy.giii.WP_015224739',\n",
       " 'decoy.giii.WP_015228142',\n",
       " 'decoy.giii.WP_015228746',\n",
       " 'decoy.giii.WP_015228929',\n",
       " 'decoy.giii.WP_015229728',\n",
       " 'decoy.giii.WP_015230687',\n",
       " 'decoy.giii.WP_015246860',\n",
       " 'decoy.giii.WP_015255016',\n",
       " 'decoy.giii.WP_015255371',\n",
       " 'decoy.giii.WP_015255396',\n",
       " 'decoy.giii.WP_015256414',\n",
       " 'decoy.giii.WP_015265958',\n",
       " 'decoy.giii.WP_015279466',\n",
       " 'decoy.giii.WP_015310926',\n",
       " 'decoy.giii.WP_015313885',\n",
       " 'decoy.giii.WP_015324543',\n",
       " 'decoy.giii.WP_015326080',\n",
       " 'decoy.giii.WP_015326130',\n",
       " 'decoy.giii.WP_015404462',\n",
       " 'decoy.giii.WP_015448732',\n",
       " 'decoy.giii.WP_015751077',\n",
       " 'decoy.giii.WP_015751079',\n",
       " 'decoy.giii.WP_015751298',\n",
       " 'decoy.giii.WP_015757381',\n",
       " 'decoy.giii.WP_015759379',\n",
       " 'decoy.giii.WP_015767619',\n",
       " 'decoy.giii.WP_015868658',\n",
       " 'decoy.giii.WP_015926128',\n",
       " 'decoy.giii.WP_020458937',\n",
       " 'decoy.giii.WP_020458991',\n",
       " 'decoy.giii.WP_020460956',\n",
       " 'decoy.giii.WP_020479258',\n",
       " 'decoy.giii.WP_021007781',\n",
       " 'decoy.giii.WP_022774790',\n",
       " 'decoy.giii.WP_024266609',\n",
       " 'decoy.giii.WP_024268540',\n",
       " 'decoy.giii.WP_025279452',\n",
       " 'decoy.giii.WP_025435133',\n",
       " 'decoy.giii.WP_025436803',\n",
       " 'decoy.giii.WP_028170458',\n",
       " 'decoy.giii.WP_031445652',\n",
       " 'decoy.giii.WP_033260169',\n",
       " 'decoy.giii.WP_037306590',\n",
       " 'decoy.giii.WP_038556923',\n",
       " 'decoy.giii.WP_038635474',\n",
       " 'decoy.giii.WP_038652799',\n",
       " 'decoy.giii.WP_038657050',\n",
       " 'decoy.giii.WP_039123471',\n",
       " 'decoy.giii.WP_039959348',\n",
       " 'decoy.giii.WP_040202782',\n",
       " 'decoy.giii.WP_040608979',\n",
       " 'decoy.giii.WP_041314106',\n",
       " 'decoy.giii.WP_041358447',\n",
       " 'decoy.giii.WP_041544159',\n",
       " 'decoy.giii.WP_041558265',\n",
       " 'decoy.giii.WP_041587637',\n",
       " 'decoy.giii.WP_041607653',\n",
       " 'decoy.giii.WP_041649442',\n",
       " 'decoy.giii.WP_041657898',\n",
       " 'decoy.giii.WP_042258399',\n",
       " 'decoy.giii.WP_043739865',\n",
       " 'decoy.giii.WP_044024589',\n",
       " 'decoy.giii.WP_044137028',\n",
       " 'decoy.giii.WP_044236475',\n",
       " 'decoy.giii.WP_044898652',\n",
       " 'decoy.giii.WP_045362297',\n",
       " 'decoy.giii.WP_045362644',\n",
       " 'decoy.giii.WP_045363980',\n",
       " 'decoy.giii.WP_045366062',\n",
       " 'decoy.giii.WP_046008820',\n",
       " 'decoy.giii.WP_046009289',\n",
       " 'decoy.giii.WP_046314815',\n",
       " 'decoy.giii.WP_046328154',\n",
       " 'decoy.giii.WP_047372121',\n",
       " 'decoy.giii.WP_049778549',\n",
       " 'decoy.giii.WP_049802798',\n",
       " 'decoy.giii.WP_050766313',\n",
       " 'decoy.giii.WP_051005615',\n",
       " 'decoy.giii.WP_051030593',\n",
       " 'decoy.giii.WP_051036029',\n",
       " 'decoy.giii.WP_051908353',\n",
       " 'decoy.giii.WP_052304322',\n",
       " 'decoy.giii.WP_052739171',\n",
       " 'decoy.giii.WP_052882609',\n",
       " 'decoy.giii.WP_052882963',\n",
       " 'decoy.giii.WP_053102516',\n",
       " 'decoy.giii.WP_053335774',\n",
       " 'decoy.giii.WP_058258314',\n",
       " 'decoy.giii.WP_058885303',\n",
       " 'decoy.giii.WP_060684661',\n",
       " 'decoy.giii.WP_060685564',\n",
       " 'decoy.giii.WP_060690008',\n",
       " 'decoy.giii.WP_060690496',\n",
       " 'decoy.giii.WP_063464380',\n",
       " 'decoy.giii.WP_065534175',\n",
       " 'decoy.giii.WP_066050611',\n",
       " 'decoy.giii.WP_066050750',\n",
       " 'decoy.giii.WP_066050931',\n",
       " 'decoy.giii.WP_066053905',\n",
       " 'decoy.giii.WP_066076933',\n",
       " 'decoy.giii.WP_066970370',\n",
       " 'decoy.giii.WP_068444960',\n",
       " 'decoy.giii.WP_068445309',\n",
       " 'decoy.giii.WP_068759647',\n",
       " 'decoy.giii.WP_068960681',\n",
       " 'decoy.giii.WP_069709771',\n",
       " 'decoy.giii.WP_069859434',\n",
       " 'decoy.giii.WP_070390923',\n",
       " 'decoy.giii.WP_070391404',\n",
       " 'decoy.giii.WP_070392078',\n",
       " 'decoy.giii.WP_070395278',\n",
       " 'decoy.giii.WP_071137175',\n",
       " 'decoy.giii.WP_071138112',\n",
       " 'decoy.giii.WP_071138336',\n",
       " 'decoy.giii.WP_072432526',\n",
       " 'decoy.giii.WP_075097771',\n",
       " 'decoy.giii.WP_075261577',\n",
       " 'decoy.giii.WP_075303169',\n",
       " 'decoy.giii.WP_075574302',\n",
       " 'decoy.giii.WP_076376431',\n",
       " 'decoy.giii.WP_077028093',\n",
       " 'decoy.giii.WP_077028158',\n",
       " 'decoy.giii.WP_077352018',\n",
       " 'decoy.giii.WP_080039326',\n",
       " 'decoy.giii.WP_080513203',\n",
       " 'decoy.giii.WP_080666776',\n",
       " 'decoy.giii.WP_080806088',\n",
       " 'decoy.giii.WP_080809480',\n",
       " 'decoy.giii.WP_081421633',\n",
       " 'decoy.giii.WP_081470816',\n",
       " 'decoy.giii.WP_081480208',\n",
       " 'decoy.giii.WP_081480226',\n",
       " 'decoy.giii.WP_081598311',\n",
       " 'decoy.giii.WP_082076235',\n",
       " 'decoy.giii.WP_082175079',\n",
       " 'decoy.giii.WP_082342742',\n",
       " 'decoy.giii.WP_082679778',\n",
       " 'decoy.giii.WP_082725996',\n",
       " 'decoy.giii.WP_083305223',\n",
       " 'decoy.giii.WP_083499360',\n",
       " 'decoy.giii.WP_083771393',\n",
       " 'decoy.giii.WP_083774309',\n",
       " 'decoy.giii.WP_083855505',\n",
       " 'decoy.giii.WP_083858499',\n",
       " 'decoy.giii.WP_083892009',\n",
       " 'decoy.giii.WP_085755015',\n",
       " 'decoy.giii.WP_085756395',\n",
       " 'decoy.giii.WP_085953607',\n",
       " 'decoy.giii.WP_085953929',\n",
       " 'decoy.giii.WP_085988589',\n",
       " 'decoy.giii.WP_086003137',\n",
       " 'decoy.giii.WP_087464575',\n",
       " 'decoy.giii.WP_088328704',\n",
       " 'decoy.giii.WP_088621217',\n",
       " 'decoy.giii.WP_088872173',\n",
       " 'decoy.giii.WP_088915895',\n",
       " 'decoy.giii.WP_088917071',\n",
       " 'decoy.giii.WP_088917077',\n",
       " 'decoy.giii.WP_088919225',\n",
       " 'decoy.giii.WP_089416014',\n",
       " 'decoy.giii.WP_089610017',\n",
       " 'decoy.giii.WP_093977904',\n",
       " 'decoy.giii.WP_095992268',\n",
       " 'decoy.giii.WP_096240995',\n",
       " 'decoy.giii.WP_096360045',\n",
       " 'decoy.giii.WP_096458013',\n",
       " 'decoy.giii.WP_096462144',\n",
       " 'decoy.giii.WP_096462550',\n",
       " 'decoy.giii.WP_096717362',\n",
       " 'decoy.giii.WP_096719208',\n",
       " 'decoy.giii.WP_096719658',\n",
       " 'decoy.giii.WP_096723591',\n",
       " 'decoy.giii.WP_096723646',\n",
       " 'decoy.giii.WP_096723732',\n",
       " 'decoy.giii.WP_096723977',\n",
       " 'decoy.giii.WP_099325839',\n",
       " 'decoy.giii.WP_099326186',\n",
       " 'decoy.giii.WP_099512285',\n",
       " 'decoy.giii.WP_100919280',\n",
       " 'decoy.giii.WP_100920184',\n",
       " 'decoy.giii.WP_100922120',\n",
       " 'decoy.giii.WP_102992301',\n",
       " 'decoy.giii.WP_103083197',\n",
       " 'decoy.giii.WP_103083307',\n",
       " 'decoy.giii.WP_104010087',\n",
       " 'decoy.giii.WP_105885468',\n",
       " 'decoy.giii.WP_106447946',\n",
       " 'decoy.giii.WP_106790303',\n",
       " 'decoy.giii.WP_106874743',\n",
       " 'decoy.giii.WP_108081062',\n",
       " 'decoy.giii.WP_108602111',\n",
       " 'decoy.giii.WP_108603064',\n",
       " 'decoy.giii.WP_108614910',\n",
       " 'decoy.giii.WP_108615237',\n",
       " 'decoy.giii.WP_110136160',\n",
       " 'decoy.giii.WP_110136722',\n",
       " 'decoy.giii.WP_111370339',\n",
       " 'decoy.giii.WP_114910998',\n",
       " 'decoy.giii.WP_114930545',\n",
       " 'decoy.giii.WP_117328626',\n",
       " 'decoy.giii.WP_119050297',\n",
       " 'decoy.giii.WP_119628314',\n",
       " 'decoy.giii.WP_119631381',\n",
       " 'decoy.giii.WP_119984315',\n",
       " 'decoy.giii.WP_121047055',\n",
       " 'decoy.giii.WP_121813216',\n",
       " 'decoy.giii.WP_125125479',\n",
       " 'decoy.giii.WP_125989631',\n",
       " 'decoy.giii.WP_125989641',\n",
       " 'decoy.giii.WP_125990031',\n",
       " 'decoy.giii.WP_125990810',\n",
       " 'decoy.giii.WP_126353939',\n",
       " 'decoy.giii.WP_127026497',\n",
       " 'decoy.giii.WP_127074879',\n",
       " 'decoy.giii.WP_128425094',\n",
       " 'decoy.giii.WP_128745892',\n",
       " 'decoy.giii.WP_128751685',\n",
       " 'decoy.giii.WP_128753262',\n",
       " 'decoy.giii.WP_128753412',\n",
       " 'decoy.giii.WP_129888976',\n",
       " 'decoy.giii.WP_129888978',\n",
       " 'decoy.giii.WP_129891666',\n",
       " 'decoy.giii.WP_129894803',\n",
       " 'decoy.giii.WP_130536641']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ids[x] for x in fp_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e622f",
   "metadata": {},
   "source": [
    "### Joined metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4176dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>serratusL</th>\n",
       "      <td>0.715492</td>\n",
       "      <td>0.628389</td>\n",
       "      <td>0.557879</td>\n",
       "      <td>0.997233</td>\n",
       "      <td>0.303176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serratusL_other</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palmcore</th>\n",
       "      <td>0.955782</td>\n",
       "      <td>0.915577</td>\n",
       "      <td>0.916949</td>\n",
       "      <td>0.998049</td>\n",
       "      <td>0.036952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       f1  accuracy  precision    recall  specificity\n",
       "serratusL        0.715492  0.628389   0.557879  0.997233     0.303176\n",
       "serratusL_other  0.000000  0.686000   0.000000  0.000000     0.686000\n",
       "palmcore         0.955782  0.915577   0.916949  0.998049     0.036952"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    \"serratusL\": serratusL_metrics,\n",
    "    \"serratusL_other\": serratusOther_metrics,\n",
    "    \"palmcore\": palmcore_metrics,\n",
    "})\n",
    "\n",
    "metrics_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358c30e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "761dcf3000c2b57fce1705285a4edc685c7921b9b6d947da8814dacfe91028c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
