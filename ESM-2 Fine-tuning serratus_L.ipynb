{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfdba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    EsmForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4d7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PRETRAINED = \"esm2_t6_8M_UR50D\" # Path to the pre-trained ESM model\n",
    "BATCH_SIZE = 10 # Training batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c3a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(path: str, min_length=200, max_length=1024):\n",
    "    \"\"\"\n",
    "    Reads a fasta file and returns a list of sequences, and a list of sequence identifiers. \n",
    "    Sequences are filtered out if shorter than `min_length`, and truncated if longer than `max_length`.\n",
    "    \"\"\"\n",
    "    sequences, ids = [], []\n",
    "    sequence = \"\"\n",
    "    with open(path, \"r\") as fasta:\n",
    "        for line in fasta:\n",
    "            if line.startswith(\">\"):\n",
    "                if len(sequence) >= min_length:\n",
    "                    ids.append(line[1:].strip())\n",
    "                    sequences.append(sequence[:max_length])\n",
    "                sequence = \"\"\n",
    "                continue\n",
    "            sequence += line.strip()\n",
    "    if len(sequence) >= min_length:\n",
    "        ids.append(line[1:].strip())\n",
    "        sequences.append(sequence[:max_length])\n",
    "    \n",
    "    return sequences, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778669e",
   "metadata": {},
   "source": [
    "# Data Loading and preparation\n",
    "\n",
    "We use a dataset derived from SerratusL for training: \n",
    "\n",
    "## Importing and formatting data\n",
    "\n",
    "The data used as input for the ESM based classifier is the set of raw sequences, truncated to a max length of 1024.  \n",
    "The labels are `1` for RDRP sequences and `0` for Non-RDRP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea6cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/eval/serratusL-negdepleted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc42301",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sequences = df[df[\"type\"] == \"rdrp\"][\"seq\"].values.tolist()\n",
    "pos_labels = [1 for _ in pos_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0bf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sequences = df[df[\"type\"] != \"rdrp\"][\"seq\"].values.tolist()\n",
    "neg_labels = [0 for _ in neg_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91325507",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pos_sequences + neg_sequences\n",
    "labels = pos_labels + neg_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584d8a7",
   "metadata": {},
   "source": [
    "## Making datasets \n",
    "The data is then split into a training and a testing set, the sequences in each set are then tokenized using the included pretrained Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c0f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "train_sequences, test_sequences, train_labels, test_labels = (\n",
    "    train_test_split(sequences, labels, test_size=0.25, shuffle=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e24b8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PRETRAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02df30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize inputs\n",
    "train_tokenized = tokenizer(train_sequences)\n",
    "test_tokenized = tokenizer(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e28dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "\n",
    "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d6e2d",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "The sequence classifier is trained on the created dataset. Since the training data is imbalanced *(5k pos for 10k neg)* we use the F1 score to train model.  \n",
    "For evaluation we compute several metrics, to get an overall view of how the model performs:  \n",
    " - F1\n",
    " - Accuracy\n",
    " - Precision\n",
    " - Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "572225b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/tmp/ipykernel_4014401/2976490373.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metrics = [load_metric(path) for path in metric_paths]\n"
     ]
    }
   ],
   "source": [
    "metric_paths = [\"./metrics/f1\", \"./metrics/accuracy\", \"./metrics/precision\", \"./metrics/recall\"]\n",
    "metrics = [load_metric(path) for path in metric_paths]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    scores = dict()\n",
    "    for metric in metrics:\n",
    "        scores.update(\n",
    "            metric.compute(predictions=predictions, references=labels)\n",
    "        )\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9163eebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at esm2_t6_8M_UR50D were not used when initializing EsmForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing EsmForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at esm2_t6_8M_UR50D and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 2 # Binary classifier\n",
    "model = EsmForSequenceClassification.from_pretrained(\n",
    "    MODEL_PRETRAINED, num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da05ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_args = TrainingArguments(\n",
    "    f\"{MODEL_PRETRAINED}-finetuned-serratusL\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1354a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    trainer_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4905012e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/zeus/projets/p01/Evolbioinfo/users/lblassel/miniconda3/envs/palm-fold2/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 32976\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9894\n",
      "  Number of trainable parameters = 7840642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9894' max='9894' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9894/9894 08:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.119739</td>\n",
       "      <td>0.967083</td>\n",
       "      <td>0.968341</td>\n",
       "      <td>0.949304</td>\n",
       "      <td>0.985541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.112240</td>\n",
       "      <td>0.972338</td>\n",
       "      <td>0.973435</td>\n",
       "      <td>0.955858</td>\n",
       "      <td>0.989397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.115589</td>\n",
       "      <td>0.972746</td>\n",
       "      <td>0.973981</td>\n",
       "      <td>0.961749</td>\n",
       "      <td>0.983998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10992\n",
      "  Batch size = 10\n",
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-3298\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-3298/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-3298/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-3298/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-3298/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10992\n",
      "  Batch size = 10\n",
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-6596\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-6596/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-6596/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-6596/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-6596/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10992\n",
      "  Batch size = 10\n",
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-9894\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-9894/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-9894/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-9894/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-9894/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from esm2_t6_8M_UR50D-finetuned-serratusL/checkpoint-9894 (score: 0.9727463312368972).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9894, training_loss=0.10503221353377047, metrics={'train_runtime': 516.1023, 'train_samples_per_second': 191.683, 'train_steps_per_second': 19.171, 'total_flos': 1135465496038080.0, 'train_loss': 0.10503221353377047, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edf787e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-serratusL\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-serratusL/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-serratusL/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-serratusL/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-serratusL/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ae5ec",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "the model is then evaluated on a number of datasets:  \n",
    " - wolf2018 positive sequences (`datasets/wolf2018.fa`)\n",
    " - tricky decoys (`datasets/rdrp_decoy.10k.fa`)\n",
    " - Other SerratusL negative sequences (`datasets/eval/other-negs.csv`)\n",
    " - ~~CFDL sequences (`datasets/eval/CFDL-sample.fa`)~~\n",
    " - Palmcore decoys (`datasets/eval/palmcores.fa`)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "636c43ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file esm2_t6_8M_UR50D-finetuned-serratusL/config.json\n",
      "Model config EsmConfig {\n",
      "  \"_name_or_path\": \"esm2_t6_8M_UR50D\",\n",
      "  \"architectures\": [\n",
      "    \"EsmForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_layer_norm_before\": false,\n",
      "  \"esmfold_config\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 320,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1280,\n",
      "  \"is_folding_model\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"mask_token_id\": 32,\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"esm\",\n",
      "  \"num_attention_heads\": 20,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"rotary\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"token_dropout\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_list\": null,\n",
      "  \"vocab_size\": 33\n",
      "}\n",
      "\n",
      "loading weights file esm2_t6_8M_UR50D-finetuned-serratusL/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing EsmForSequenceClassification.\n",
      "\n",
      "All the weights of EsmForSequenceClassification were initialized from the model checkpoint at esm2_t6_8M_UR50D-finetuned-serratusL.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use EsmForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "eval_tokenizer = AutoTokenizer.from_pretrained(f\"{MODEL_PRETRAINED}-finetuned-serratusL\")\n",
    "eval_model = EsmForSequenceClassification.from_pretrained(f\"{MODEL_PRETRAINED}-finetuned-serratusL\", num_labels=2)\n",
    "trainer = Trainer(\n",
    "    eval_model,\n",
    "    trainer_args,\n",
    "    tokenizer=eval_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff7ccc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_specificity(predictions, labels):\n",
    "    counts = Counter(zip(labels, predictions))\n",
    "    \n",
    "    TP, TN = counts[(1,1)], counts[(0,0)]\n",
    "    FP, FN = counts[(0,1)], counts[(1,0)]\n",
    "    \n",
    "    if TN + FP == 0: return 0 \n",
    "    \n",
    "    return TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1731b0a5",
   "metadata": {},
   "source": [
    "### Wolf2018 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62d5d143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4627\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.9821821381434228, 'accuracy': 0.964988113248325, 'precision': 1.0, 'recall': 0.964988113248325, 'specificity': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1123592258',\n",
       " '501421962',\n",
       " '489297600',\n",
       " '919371179',\n",
       " '946694699',\n",
       " '1062933037',\n",
       " '923750907',\n",
       " '1025017799',\n",
       " '390353251',\n",
       " 'APG77107.1|Changjiang_narna_like_virus_5',\n",
       " 'APG77159.1|Hubei_narna_like_virus_20',\n",
       " 'YP_009330065.1|Hubei_narna_like_virus_18',\n",
       " 'YP_009336688.1|Sanxia_water_strider_virus_13',\n",
       " 'YP_009329842.1|Hubei_narna_like_virus_24',\n",
       " 'YP_009336767.1|Hubei_narna_like_virus_23',\n",
       " 'AIF33766.2|Heterobasidion_mitovirus_1',\n",
       " 'YP_009009144.1|Sclerotinia_sclerotiorum_mitovirus_6',\n",
       " 'AHI43534.1|Fusarium_circinatum_mitovirus_2_1',\n",
       " 'YP_009259483.1|Cronartium_ribicola_mitovirus_4',\n",
       " 'AGW51760.1|Mitovirus_AEF_2013',\n",
       " 'AHX84135.1|Sclerotinia_sclerotiorum_mitovirus_7',\n",
       " 'AHF48631.1|Sclerotinia_sclerotiorum_mitovirus_15',\n",
       " 'AHX84129.1|Sclerotinia_sclerotiorum_mitovirus_2',\n",
       " 'ALM62243.1|Soybean_leaf_associated_mitovirus_3',\n",
       " 'AAA66950.1|Southern_bean_mosaic_virus',\n",
       " 'YP_004869651.2|Soybean_yellow_common_mosaic_virus',\n",
       " 'YP_009140472.1|Cymbidium_chlorotic_mosaic_virus',\n",
       " 'NP_941957.2|Cocksfoot_mottle_virus',\n",
       " 'YP_009336876.1|Beihai_sobemo_like_virus_4',\n",
       " 'YP_009330007.1|Hubei_sobemo_like_virus_5',\n",
       " 'YP_009342322.1|Wuhan_insect_virus_19',\n",
       " 'YP_009130641.1|Chinook_salmon_bafinivirus',\n",
       " 'YP_007697636.1|Meno_virus',\n",
       " 'AGI52414.1|Moumo_virus',\n",
       " 'APG78198.1|Beihai_picobirna_like_virus_11',\n",
       " 'APG78338.1|Wenling_picobirna_like_virus_1',\n",
       " 'YP_001274391.1|Fragaria_chiloensis_cryptic_virus',\n",
       " 'AAL79540.1|Heterobasidion_annosum_P_type_partitivirus',\n",
       " 'AHU88025.1|Ustilaginoidea_virens_partitivirus_2',\n",
       " 'APG78352.1|Wenzhou_partiti_like_virus_1',\n",
       " 'SBT85169.1|Cassava_brown_streak_virus',\n",
       " 'AAL71892.1|Tuberose_mild_mosaic_virus',\n",
       " 'YP_006989380.1|Ornithogalum_mosaic_virus',\n",
       " 'YP_009333573.1|Beihai_picorna_like_virus_21',\n",
       " 'YP_009342326.1|Wuhan_house_centipede_virus_2',\n",
       " 'BAM78287.1|Gentian_Kobu_sho_associated_virus',\n",
       " 'ACJ64915.2|T_Ho_virus',\n",
       " 'AGK41021.1|Bat_hepacivirus',\n",
       " 'YP_319827.1|Alstroemeria_virus_x',\n",
       " 'AQM49922.1|Agaricus_bisporus_virus_7',\n",
       " 'APQ43035.1|Bastrovirus_VietNam_Bat_16715_30',\n",
       " 'YP_009337681.1|Hubei_endorna_like_virus_1',\n",
       " 'APA23091.1|Cowpea_tombusvirid_1',\n",
       " 'YP_009011225.1|Anopheline_associated_C_virus',\n",
       " 'APG76502.1|Hubei_noda_like_virus_4',\n",
       " 'APG76091.1|Hubei_noda_like_virus_11',\n",
       " 'ADF97523.1|Alphanodavirus_HB_2007_CHN',\n",
       " 'APG76311.1|Hubei_noda_like_virus_12',\n",
       " 'YP_009333611.1|Beihai_shrimp_virus_6',\n",
       " 'APG76286.1|Beihai_noda_like_virus_13',\n",
       " 'APG76200.1|Beihai_noda_like_virus_20',\n",
       " 'YP_002600763.2|Pseudomonas_phage_phi2954',\n",
       " 'APG79149.1|Hubei_reo_like_virus_10',\n",
       " 'AQU42768.1|Morris_orbivirus',\n",
       " 'ALL54833.1|African_horse_sickness_virus_1',\n",
       " 'YP_009345879.1|Orbivirus_SX_2017a',\n",
       " 'AFH41519.1|Pata_virus',\n",
       " 'YP_009158877.1|Wad_Medani_virus',\n",
       " 'AIV43186.1|Changuinola_virus',\n",
       " 'YP_460038.1|Peruvian_horse_sickness_virus',\n",
       " 'AGG38806.1|Grass_carp_reovirus',\n",
       " 'AED99918.1|Avian_orthoreovirus',\n",
       " 'YP_003717773.1|Broome_virus',\n",
       " 'APG75996.1|Beihai_paphia_shell_virus_5',\n",
       " 'NP_108651.1|Eimeria_brunetti_RNA_virus_1',\n",
       " 'ABX79997.1|Aspergillus_mycovirus_341',\n",
       " 'ALD89129.2|Rhizoctonia_solani_negative_stranded_virus_1',\n",
       " 'YP_009330274.1|Beihai_sesarmid_crab_virus_3',\n",
       " 'YP_009333151.1|Wenling_chuvirus_like_virus_2',\n",
       " 'YP_009325368.1|Variegated_squirrel_bornavirus_1',\n",
       " 'YP_009337182.1|Hubei_diptera_virus_11',\n",
       " 'AOR51378.1|Gambie_virus',\n",
       " 'YP_009330105.1|Hubei_myriapoda_virus_7',\n",
       " 'AIY25911.1|Lepeophtheirus_salmonis_rhabdovirus_No9',\n",
       " 'YP_004928143.1|Lloviu_cuevavirus',\n",
       " 'AEB21199.1|Hendra_henipavirus',\n",
       " 'YP_009094339.1|Salem_virus',\n",
       " 'YP_009270651.1|Wuhan_Insect_virus_2',\n",
       " 'ANW72256.1|Terena_virus',\n",
       " 'APG79271.1|Hubei_bunya_like_virus_10',\n",
       " 'AIA24562.1|Nome_phantom_virus',\n",
       " 'YP_009304995.1|Wuchang_Cockroach_Virus_1',\n",
       " 'AJG39252.1|Shuangao_Mosquito_Virus',\n",
       " 'AHA83412.1|Xinyi_virus',\n",
       " 'APG79327.1|Hubei_bunya_like_virus_7',\n",
       " 'APG79361.1|Hubei_orthoptera_virus_2',\n",
       " 'AML03165.1|Wheat_mosaic_virus',\n",
       " 'AEO95760.1|Redbud_yellow_ringspot_virus',\n",
       " 'CEJ20912.1|Pigeonpea_sterility_mosaic_virus_2',\n",
       " 'YP_009237282.1|Pigeon_pea_sterility_mosaic_virus',\n",
       " 'BAM13785.1|Fig_mosaic_emaravirus',\n",
       " 'YP_003104764.1|European_mountain_ash_ringspot_associated_emaravirus',\n",
       " 'ALX00127.1|Actinidia_chlorotic_ringspot_associated_virus',\n",
       " 'AMR73398.1|Yacaaba_virus',\n",
       " 'AOZ21156.1|Gan_Gan_virus',\n",
       " 'AIN55741.1|Pacui_virus',\n",
       " 'AJD77610.1|Buffalo_Creek_virus',\n",
       " 'AKO90162.1|Lukuni_virus',\n",
       " 'AIN55747.1|Tapirape_virus',\n",
       " 'AKC42494.1|Guaroa_virus',\n",
       " 'AKO90168.1|Witwatersrand_virus',\n",
       " 'AEA02985.1|Leanyer_virus',\n",
       " 'ANI69984.1|Bellavista_virus',\n",
       " 'AIN37024.1|Mojui_dos_Campos_virus',\n",
       " 'ACV95628.1|Tensaw_virus',\n",
       " 'AGW82130.1|Oriboca_virus',\n",
       " 'YP_008400138.1|Brazoran_virus',\n",
       " 'AGS56984.1|Oya_virus',\n",
       " 'AIN37021.1|Nyando_virus',\n",
       " 'AKO90160.1|Guama_virus',\n",
       " 'AEE01391.1|Oyo_virus',\n",
       " 'AKO90169.1|Matruh_virus',\n",
       " 'AEZ35261.1|Macaua_virus',\n",
       " 'AMR98952.1|Enseada_virus',\n",
       " 'AIN37025.1|Kaeng_Khoi_virus',\n",
       " 'AJT39489.1|Oropouche_virus',\n",
       " 'APM83098.1|Mirim_virus',\n",
       " 'AHY22338.1|Buttonwillow_virus',\n",
       " 'AJG39233.1|Wuhan_Louse_Fly_Virus_1',\n",
       " 'AJT55735.1|Tete_orthobunyavirus',\n",
       " 'AFH96035.1|Akabane_virus',\n",
       " 'AHY22330.1|Facey_s_Paddock_virus',\n",
       " '5AMR_A|La_Crosse_virus',\n",
       " 'AOS59868.1|Inkoo_virus',\n",
       " 'AGX32058.1|Kibale_virus',\n",
       " 'AGX32061.1|Herbert_virus',\n",
       " 'AJG39257.1|Whenzhou_Shrimp_Virus_2',\n",
       " 'APG79313.1|Shahe_bunya_like_virus_3',\n",
       " 'ARB16032.1|Grotenhout_virus',\n",
       " 'AKC89352.1|Artashat_virus',\n",
       " 'AKC89349.1|Burana_virus',\n",
       " 'ALD84349.1|Kasokero_virus',\n",
       " 'BAU51655.1|Tofla_virus',\n",
       " 'ABY82502.1|Kupe_virus',\n",
       " 'AIZ00432.1|Nairobi_sheep_disease_virus',\n",
       " 'AJG39266.1|Wuhan_Millipede_Virus_2',\n",
       " 'AOX47534.1|Pidgey_bunyavirus',\n",
       " 'APG79267.1|Hubei_bunya_like_virus_3',\n",
       " 'AKN10711.1|Haartman_Institute_snake_virus',\n",
       " 'AKH49085.1|unidentified_Reptarenavirus',\n",
       " 'APX61223.1|Tavallinen_suomalainen_mies_virus',\n",
       " 'YP_001936024.1|Flexal_mammarenavirus',\n",
       " 'AAP44541.2|Pirital_mammarenavirus',\n",
       " 'YP_001649214.1|Oliveros_mammarenavirus',\n",
       " 'AHW46357.1|Tacaribe_mammarenavirus',\n",
       " 'APG79353.1|Wenzhou_channeled_applesnail_virus_4',\n",
       " 'AJG39095.1|Wuhan_Mosquito_Virus_7',\n",
       " 'AFN73049.1|Tjuloc_virus',\n",
       " 'AJG39085.1|Jiujie_Fly_Virus',\n",
       " 'BAS21821.1|Influenza_A_virus_A_duck_Vietnam_HU1_637_2014_H6N6_',\n",
       " 'ADE75156.1|Influenza_A_virus_A_mallard_Sweden_41_2002_H10N6_',\n",
       " 'YP_009246481.1|Tilapia_lake_virus']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences, ids = read_fasta(\"datasets/wolf2018.fa\")\n",
    "labels = [1 for _ in sequences]\n",
    "tokens = eval_tokenizer(sequences)\n",
    "\n",
    "wolf2018_dataset = Dataset.from_dict(tokens)\n",
    "pred_probas = trainer.predict(wolf2018_dataset)\n",
    "wolf2018_metrics = trainer.compute_metrics((pred_probas.predictions, labels))\n",
    "\n",
    "wolf2018_metrics[\"specificity\"] = compute_specificity(\n",
    "    np.argmax(pred_probas.predictions, axis=-1), labels\n",
    ")\n",
    "\n",
    "print(wolf2018_metrics)\n",
    "\n",
    "predictions = np.argmax(pred_probas.predictions, axis=1)\n",
    "couples = [(p,t) for p,t in zip(predictions, labels)]\n",
    "tp_idx = [i for i, (p,t) in enumerate(couples) if p==t]\n",
    "fn_idx = [i for i, (p,t) in enumerate(couples) if p!=t]\n",
    "\n",
    "wolf2018_fns = [ids[x] for x in fn_idx]\n",
    "wolf2018_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ddf04a",
   "metadata": {},
   "source": [
    "### Tricky decoy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3495ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 7366\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.0, 'accuracy': 0.9933478142818355, 'precision': 0.0, 'recall': 0.0, 'specificity': 0.9933478142818355}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/zeus/projets/p01/Evolbioinfo/users/lblassel/miniconda3/envs/palm-fold2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['WP_025353893_1 peptidase M24 family protein [Kutzneria albida]',\n",
       " 'WP_043739048_1 transketolase [Thioalkalivibrio nitratireducens]',\n",
       " 'WP_013762692_1 aspartate aminotransferase family protein [Haliscomenobacter hydrossis]',\n",
       " 'WP_011771135_1 50S ribosomal protein L13 [Psychromonas ingrahamii]',\n",
       " 'WP_011414694_1 nucleoside-diphosphate kinase [Erythrobacter litoralis]',\n",
       " 'WP_099339856_1 D-amino-acid transaminase [Candidatus Fonsibacter ubiquis]',\n",
       " 'YP_003613465_1 galactokinase [Enterobacter cloacae subsp. cloacae ATCC 13047]',\n",
       " 'WP_014261837_1 glutamine synthetase [Filifactor alocis]',\n",
       " 'WP_015935410_1 MULTISPECIES: type I glutamate--ammonia ligase [Anaeromyxobacter]',\n",
       " 'WP_011769510_1 ribonucleotide-diphosphate reductase subunit beta [Psychromonas ingrahamii]',\n",
       " 'WP_012909532_1 vitamin B12-dependent ribonucleotide reductase [Pirellula staleyi]',\n",
       " 'WP_066635279_1 glucose-6-phosphate dehydrogenase [Serinicoccus sp. JLT9]',\n",
       " 'WP_081598702_1 citrate synthase/methylcitrate synthase [Tistrella mobilis]',\n",
       " 'WP_085784766_1 deoxyribodipyrimidine photo-lyase [Candidatus Nucleicultrix amoebiphila]',\n",
       " 'WP_013798461_1 proline--tRNA ligase [Methanotorris igneus]',\n",
       " 'NP_295179_1 ribose-phosphate pyrophosphokinase [Deinococcus radiodurans R1]',\n",
       " 'WP_046019971_1 3-isopropylmalate dehydrogenase [Magnetospira sp. QH-2]',\n",
       " 'WP_075792697_1 3-isopropylmalate dehydrogenase [Massilia putida]',\n",
       " 'WP_119680847_1 tartrate dehydrogenase [Indioceanicola profundi]',\n",
       " 'WP_012606555_1 MULTISPECIES: NADP-dependent isocitrate dehydrogenase [Bacteria]',\n",
       " 'NP_274320_1 30S ribosomal protein S1 [Neisseria meningitidis MC58]',\n",
       " 'WP_027788472_1 MULTISPECIES: anthranilate phosphoribosyltransferase [Burkholderia]',\n",
       " 'WP_012079036_1 amino-acid N-acetyltransferase [Janthinobacterium sp. Marseille]',\n",
       " 'WP_012049185_1 MULTISPECIES: NADH-quinone oxidoreductase subunit D [Sphingomonas]',\n",
       " 'WP_012824815_1 NADH-quinone oxidoreductase subunit NuoD [Halothiobacillus neapolitanus]',\n",
       " 'WP_012554880_1 Fe-S cluster assembly protein SufD [Gluconacetobacter diazotrophicus]',\n",
       " 'WP_095845409_1 3-deoxy-7-phosphoheptulonate synthase [Gibbsiella quercinecans]',\n",
       " 'WP_071137431_1 aspartate ammonia-lyase [Petrimonas mucosa]',\n",
       " 'WP_002262910_1 NAD(P)-dependent oxidoreductase [Streptococcus mutans]',\n",
       " 'WP_048636421_1 anaerobic ribonucleoside-triphosphate reductase [Brenneria goodwinii]',\n",
       " 'WP_011456427_1 CarD family transcriptional regulator [Jannaschia sp. CCS1]',\n",
       " 'WP_010957890_1 fatty acid desaturase [Coxiella burnetii]',\n",
       " 'WP_013655889_1 D-alanyl-D-alanine carboxypeptidase [Cellulosilyticum lentocellum]',\n",
       " 'WP_052356026_1 PTS sugar transporter subunit IIA [Castellaniella defragrans]',\n",
       " 'WP_014961784_1 ribulose 1 5-bisphosphate carboxylase large subunit [Leptospirillum ferriphilum]',\n",
       " 'WP_011259238_1 flagellar motor switch protein FliN [Xanthomonas oryzae]',\n",
       " 'WP_011249295_1 HEPN domain-containing protein [Thermococcus kodakarensis]',\n",
       " 'WP_011286980_1 acyl-CoA dehydrogenase [Dechloromonas aromatica]',\n",
       " 'WP_013393146_1 acyl-CoA dehydrogenase [Achromobacter xylosoxidans]',\n",
       " 'WP_013721935_1 hypothetical protein [Alicycliphilus denitrificans]',\n",
       " 'WP_013908642_1 glutamate--cysteine ligase GCS2 [Thermodesulfatator indicus]',\n",
       " 'WP_011508073_1 succinylglutamate desuccinylase [Chromohalobacter salexigens]',\n",
       " 'WP_013663409_1 Na+/H+ antiporter NhaA [Sphingobacterium sp. 21]',\n",
       " 'WP_041546183_1 MULTISPECIES: MOSC domain-containing protein [Nocardioides]',\n",
       " 'NP_250358_1 hypothetical protein PA1667 [Pseudomonas aeruginosa PAO1]',\n",
       " 'WP_013613652_1 transposase [Odoribacter splanchnicus]',\n",
       " 'WP_015153822_1 DUF1802 domain-containing protein [Chroococcidiopsis thermalis]',\n",
       " 'WP_058118515_1 type I-C CRISPR-associated protein Cas8c/Csd1 [Intestinimonas butyriciproducens]',\n",
       " 'WP_089415582_1 type I-E CRISPR-associated protein Cse1/CasA [Vitreoscilla filiformis]']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences, ids = read_fasta(\"datasets/rdrp_decoy.10k.fa\")\n",
    "labels = [0 for _ in sequences]\n",
    "tokens = eval_tokenizer(sequences)\n",
    "\n",
    "tricky_dataset = Dataset.from_dict(tokens)\n",
    "pred_probas = trainer.predict(tricky_dataset)\n",
    "tricky_metrics = trainer.compute_metrics((pred_probas.predictions, labels))\n",
    "\n",
    "tricky_metrics[\"specificity\"] = compute_specificity(\n",
    "    np.argmax(pred_probas.predictions, axis=-1), labels\n",
    ")\n",
    "\n",
    "print(tricky_metrics)\n",
    "\n",
    "predictions = np.argmax(pred_probas.predictions, axis=1)\n",
    "decoys = [(p,t) for p,t in zip(predictions, labels) if t == 0]\n",
    "tn_idx = [i for i, (p,t) in enumerate(decoys) if p==t]\n",
    "fp_idx = [i for i, (p,t) in enumerate(decoys) if p!=t]\n",
    "\n",
    "tricky_fps = [ids[x] for x in fp_idx]\n",
    "tricky_fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63302f",
   "metadata": {},
   "source": [
    "### SerratusL other negs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44d8a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/zeus/projets/p01/Evolbioinfo/users/lblassel/miniconda3/envs/palm-fold2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.0,\n",
       " 'accuracy': 0.9891,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'specificity': 0.9891}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/eval/other-negs.csv\", header=None)\n",
    "df.columns = [\"seq\", \"type\"]\n",
    "labels = [1 if label == \"rdrp\" else 0 for label in df[\"type\"].values]\n",
    "tokens = eval_tokenizer(df[\"seq\"].values.tolist())\n",
    "\n",
    "serratusOther_dataset = Dataset.from_dict(tokens)\n",
    "\n",
    "pred_probas = trainer.predict(serratusOther_dataset)\n",
    "serratusOther_metrics = trainer.compute_metrics((pred_probas.predictions, labels))\n",
    "\n",
    "serratusOther_metrics[\"specificity\"] = compute_specificity(\n",
    "    np.argmax(pred_probas.predictions, axis=-1), labels\n",
    ")\n",
    "\n",
    "serratusOther_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88290e9",
   "metadata": {},
   "source": [
    "### Palmcore decoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb991e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 433\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.0, 'accuracy': 0.9930715935334873, 'precision': 0.0, 'recall': 0.0, 'specificity': 0.9930715935334873}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/zeus/projets/p01/Evolbioinfo/users/lblassel/miniconda3/envs/palm-fold2/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['decoy.2DY4_B', 'decoy.A0A0K0F8E6_STRVS', 'decoy.A0A4W6CRS7_LATCA']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs, ids = read_fasta(\"datasets/eval/palmcores.fa\")\n",
    "labels = [0 if \"decoy\" in id else 1 for id in ids]\n",
    "\n",
    "filtered = [\n",
    "    seq for (seq, label) in zip(seqs, labels)\n",
    "    if label == 0\n",
    "]\n",
    "labels = [0 for _ in filtered]\n",
    "\n",
    "tokens = eval_tokenizer(filtered)\n",
    "\n",
    "palmcore_dataset = Dataset.from_dict(tokens)\n",
    "\n",
    "pred_probas = trainer.predict(palmcore_dataset)\n",
    "palmcore_metrics = trainer.compute_metrics((pred_probas.predictions, labels))\n",
    "\n",
    "palmcore_metrics[\"specificity\"] = compute_specificity(\n",
    "    np.argmax(pred_probas.predictions, axis=-1), labels\n",
    ")\n",
    "\n",
    "print(palmcore_metrics)\n",
    "\n",
    "predictions = np.argmax(pred_probas.predictions, axis=1)\n",
    "decoys = [(p,t) for p,t in zip(predictions, labels) if t == 0]\n",
    "tn_idx = [i for i, (p,t) in enumerate(decoys) if p==t]\n",
    "fp_idx = [i for i, (p,t) in enumerate(decoys) if p!=t]\n",
    "\n",
    "palmcore_fps = [ids[x] for x in fp_idx]\n",
    "palmcore_fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e622f",
   "metadata": {},
   "source": [
    "### Joined metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4176dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolf2018 (+)</th>\n",
       "      <td>0.964988</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdrp_decoy.10k (-)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serratusL_other_negs (-)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palmcore_decoys (-)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            recall  specificity\n",
       "wolf2018 (+)              0.964988     0.000000\n",
       "rdrp_decoy.10k (-)        0.000000     0.993348\n",
       "serratusL_other_negs (-)  0.000000     0.989100\n",
       "palmcore_decoys (-)       0.000000     0.993072"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    \"wolf2018 (+)\": wolf2018_metrics,\n",
    "    \"rdrp_decoy.10k (-)\": tricky_metrics,\n",
    "    \"serratusL_other_negs (-)\": serratusOther_metrics,\n",
    "    \"palmcore_decoys (-)\": palmcore_metrics,\n",
    "})\n",
    "\n",
    "metrics_df.transpose()[[\"recall\", \"specificity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6358c30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wolf2018 (+)</th>\n",
       "      <td>0.982182</td>\n",
       "      <td>0.964988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964988</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdrp_decoy.10k (-)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serratusL_other_negs (-)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palmcore_decoys (-)</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                f1  accuracy  precision    recall  specificity\n",
       "wolf2018 (+)              0.982182  0.964988        1.0  0.964988     0.000000\n",
       "rdrp_decoy.10k (-)        0.000000  0.993348        0.0  0.000000     0.993348\n",
       "serratusL_other_negs (-)  0.000000  0.989100        0.0  0.000000     0.989100\n",
       "palmcore_decoys (-)       0.000000  0.993072        0.0  0.000000     0.993072"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8b0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "761dcf3000c2b57fce1705285a4edc685c7921b9b6d947da8814dacfe91028c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
