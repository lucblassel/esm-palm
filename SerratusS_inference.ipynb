{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31091a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gzip\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    EsmForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490f490",
   "metadata": {},
   "source": [
    "# Pretrained model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5881959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"esm2_t6_8M_UR50D-finetuned-serratusL\"\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e13ee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/tmp/ipykernel_3560082/2976490373.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metrics = [load_metric(path) for path in metric_paths]\n"
     ]
    }
   ],
   "source": [
    "metric_paths = [\"./metrics/f1\", \"./metrics/accuracy\", \"./metrics/precision\", \"./metrics/recall\"]\n",
    "metrics = [load_metric(path) for path in metric_paths]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    scores = dict()\n",
    "    for metric in metrics:\n",
    "        scores.update(\n",
    "            metric.compute(predictions=predictions, references=labels)\n",
    "        )\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e888bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_args = TrainingArguments(\n",
    "    f\"{MODEL_NAME}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a26d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_tokenizer = AutoTokenizer.from_pretrained(f\"{MODEL_NAME}\")\n",
    "eval_model = EsmForSequenceClassification.from_pretrained(f\"{MODEL_NAME}\", num_labels=2)\n",
    "trainer = Trainer(\n",
    "    eval_model,\n",
    "    trainer_args,\n",
    "    tokenizer=eval_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bc3b4",
   "metadata": {},
   "source": [
    "# Study memory and time requirements\n",
    "Here I just load 10,000 sequences to estimate how long the inference will run for on the whole dataset of 34M sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d5222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SEQ_NUM = 34_217_821 # number of sequences in tar.gz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3958bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, ids = [], []\n",
    "with open(\"datasets/serratus_S.fasta\", \"r\") as fasta:\n",
    "    for i, line in enumerate(fasta):\n",
    "        if len(sequences) >= 10000:\n",
    "            break\n",
    "        elif line.startswith(\">\"):\n",
    "            ids.append(line[1:].split(\";\")[0])\n",
    "        else:\n",
    "            sequences.append(line.strip()[:1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2875be00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.390019190481212"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_per_seq = (sum(sys.getsizeof(x) for x in sequences) + sys.getsizeof(sequences)) / len(sequences)\n",
    "(TOTAL_SEQ_NUM * size_per_seq) / (1024 * 1024 * 1024) # approx size of sequences in GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331cde4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = eval_tokenizer(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d0223de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.692831563297659"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_per_token_seq = (sum(sys.getsizeof(x) for x in tokens) + sys.getsizeof(tokens)) / len(tokens)\n",
    "(TOTAL_SEQ_NUM * size_per_token_seq) / (1024 * 1024 * 1024) # approx size of tokenized sequences in GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0725404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75fa55b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_probas = trainer.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f0edca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:10:26.399855\n"
     ]
    }
   ],
   "source": [
    "seconds_per_seq = 1 / pred_probas.metrics[\"test_samples_per_second\"]\n",
    "print(datetime.timedelta(seconds = TOTAL_SEQ_NUM * seconds_per_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b519b6c1",
   "metadata": {},
   "source": [
    "# Full Test run on \"small dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71a5effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_batch(tokens, ids, output_path, trainer):\n",
    "    dataset = Dataset.from_list(tokens)\n",
    "    pred_probas = trainer.predict(dataset)\n",
    "    preds = pred_probas.predictions.argmax(axis=1)\n",
    "    with open(output_path, \"a\") as outfile:\n",
    "        for id_, pred in zip(ids, preds):\n",
    "            outfile.write(f\"{id_}\\t{pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07f98caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 38s, sys: 721 ms, total: 3min 38s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens, ids = [], []\n",
    "counter = 0\n",
    "res_path = f\"serratus_S.{MODEL_NAME}.inference.test.tsv\"\n",
    "with open(\"datasets/serratus_S.fasta\", \"r\") as fasta:\n",
    "    for i, line in enumerate(fasta):\n",
    "        if len(tokens) >= 10_000: # infer and predict in batches\n",
    "            infer_batch(tokens, ids, res_path, trainer)\n",
    "            tokens, ids = [], []\n",
    "        if counter >= 100_000: # max inferences\n",
    "            break\n",
    "        elif line.startswith(\">\"):\n",
    "            ids.append(line[1:].split(\";\")[0])\n",
    "        else:\n",
    "            tokens.append(eval_tokenizer(line.strip()[:1024]))\n",
    "            counter += 1\n",
    "\n",
    "if len(tokens) > 0:\n",
    "    infer_batch(tokens, ids, res_path, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3943a75",
   "metadata": {},
   "source": [
    "# Full inference\n",
    "We infer an RDRP status for all $36\\cdot10^{6}$ sequences of `datasets/serratus_S.fasta` using our `esm2_t6_UR50D` model fine-tuned on `serratusL`.  \n",
    "The inference is done on batches of 1 million sequences which are written to the output file incrementally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1c115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1000000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1000000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1000000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1000000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1000000\n",
      "  Batch size = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='81' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   81/10000 00:13 < 27:21, 6.04 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "tokens, ids = [], []\n",
    "res_path = f\"serratus_S.{MODEL_NAME}.inference.tsv\"\n",
    "\n",
    "with open(\"datasets/serratus_S.fasta\", \"r\") as fasta:\n",
    "    for i, line in enumerate(fasta):\n",
    "        \n",
    "        # Infer if batch is ready\n",
    "        if len(tokens) >= 1_000_000: \n",
    "            infer_batch(tokens, ids, res_path, trainer)\n",
    "            tokens, ids = [], []\n",
    "\n",
    "        # Fill up batch\n",
    "        if line.startswith(\">\"):\n",
    "            ids.append(line[1:].split(\";\")[0])\n",
    "        else:\n",
    "            tokens.append(eval_tokenizer(line.strip()[:1024]))\n",
    "\n",
    "# Flush incomplete batch\n",
    "if len(tokens) > 0:\n",
    "    infer_batch(tokens, ids, res_path, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76840fc0",
   "metadata": {},
   "source": [
    "(the cell above did run but the output is messed up)\n",
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d81dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"serratus_S.esm2_t6_8M_UR50D-finetuned-serratusL.inference.tsv\", sep=\"\\t\", header=None)\n",
    "results.columns = [\"id\", \"rdrp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "933d6b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rdrp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR6181341_3_1339_1890_1_ID=58989_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR7619050_2_274_1434_1_ID=41851_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERR1879302_1_3_1253_1_ID=59412_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR6917556_1_2_787_1_ID=14462_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR11673796_1_24_431_-1_ID=520071_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  rdrp\n",
       "0  SRR6181341_3_1339_1890_1_ID=58989_3     0\n",
       "1   SRR7619050_2_274_1434_1_ID=41851_2     0\n",
       "2     ERR1879302_1_3_1253_1_ID=59412_1     0\n",
       "3      SRR6917556_1_2_787_1_ID=14462_1     0\n",
       "4  SRR11673796_1_24_431_-1_ID=520071_1     0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aa34942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135,861 sequences classified as rdrp (0.40%)\n"
     ]
    }
   ],
   "source": [
    "num_hits = (results['rdrp'] == 1).sum()\n",
    "print(f\"{num_hits:,} sequences classified as rdrp ({100 * num_hits / results.shape[0]:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
